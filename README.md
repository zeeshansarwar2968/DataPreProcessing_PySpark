# DataPreProcessing_PySpark

- Storing data on on premise DB and preprocessing it using PySpark


<h4>Tasks to be accomplished </h4>

1. Use the static data - Some GBs of data
2. Store the data on on premise DB
3. Pre-process the data (Use Python + Spark)
4. Finding users with lowest & highest numbers of average hours
5. Finding users with highest numbers of times late comings & idle hours
6. Store results on BLOB Storage